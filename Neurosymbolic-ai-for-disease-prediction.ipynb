{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-31T15:18:03.079096Z","iopub.execute_input":"2023-05-31T15:18:03.079455Z","iopub.status.idle":"2023-05-31T15:18:03.122668Z","shell.execute_reply.started":"2023-05-31T15:18:03.079429Z","shell.execute_reply":"2023-05-31T15:18:03.121744Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/disease-symptom-description-dataset/symptom_Description.csv\n/kaggle/input/disease-symptom-description-dataset/Symptom-severity.csv\n/kaggle/input/disease-symptom-description-dataset/symptom_precaution.csv\n/kaggle/input/disease-symptom-description-dataset/dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\nimport networkx as nx","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:18:03.123980Z","iopub.execute_input":"2023-05-31T15:18:03.124214Z","iopub.status.idle":"2023-05-31T15:18:12.929142Z","shell.execute_reply.started":"2023-05-31T15:18:03.124168Z","shell.execute_reply":"2023-05-31T15:18:12.928112Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the datasets\nsymptom_severity_df = pd.read_csv('/kaggle/input/disease-symptom-description-dataset/Symptom-severity.csv')\ndisease_symptom_df = pd.read_csv('/kaggle/input/disease-symptom-description-dataset/dataset.csv')\ndisease_description_df = pd.read_csv('/kaggle/input/disease-symptom-description-dataset/symptom_Description.csv')\ndisease_precaution_df = pd.read_csv('/kaggle/input/disease-symptom-description-dataset/symptom_precaution.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:19:04.481939Z","iopub.execute_input":"2023-05-31T15:19:04.482643Z","iopub.status.idle":"2023-05-31T15:19:04.553763Z","shell.execute_reply.started":"2023-05-31T15:19:04.482618Z","shell.execute_reply":"2023-05-31T15:19:04.552700Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Incorporate symptom severity\nsymptom_severity_dict = dict(zip(symptom_severity_df['Symptom'], symptom_severity_df['weight']))\n\n# Create a dictionary to map symptoms to their indices\nsymptom_to_index = {symptom: index for index, symptom in enumerate(symptom_severity_dict.keys())}\n\n# Remove leading and trailing spaces from disease names in the disease_symptom_df dataset\ndisease_symptom_df['Disease'] = disease_symptom_df['Disease'].str.strip()\ndisease_symptom_df = disease_symptom_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\n# Remove leading and trailing spaces from disease names in the disease_description_df dataset\ndisease_description_df['Disease'] = disease_description_df['Disease'].str.strip()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:19:27.638731Z","iopub.execute_input":"2023-05-31T15:19:27.639093Z","iopub.status.idle":"2023-05-31T15:19:27.680297Z","shell.execute_reply.started":"2023-05-31T15:19:27.639067Z","shell.execute_reply":"2023-05-31T15:19:27.679537Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define symbolic rules\ndisease_symptom_dict = {}\nsymptom_disease_dict = {}\n\n# Normalize symptom names\nnormalize_symptom = lambda symptom: symptom.strip().lower()\n\n# Iterate over the rows of the dataset\nfor _, row in disease_symptom_df.iterrows():\n    disease = row['Disease']\n    symptoms = [normalize_symptom(symptom) for symptom in row.drop('Disease').dropna().tolist()]\n    \n    if disease in disease_symptom_dict:\n        disease_symptom_dict[disease].extend(symptoms)\n    else:\n        disease_symptom_dict[disease] = symptoms\n    \n    for symptom in symptoms:\n        if symptom in symptom_disease_dict:\n            symptom_disease_dict[symptom].append(disease)\n        else:\n            symptom_disease_dict[symptom] = [disease]\n\n# Convert patient symptoms to a one-hot encoded vector\ndef encode_symptoms(symptoms):\n    encoded = np.zeros(len(symptom_severity_dict))\n    for symptom in symptoms:\n        symptom = normalize_symptom(symptom)\n        if symptom in symptom_severity_dict and symptom in symptom_to_index:\n            severity = symptom_severity_dict[symptom]\n            encoded[symptom_to_index[symptom]] = severity\n    return encoded\n\n# Create the hybrid model\nsymptom_input = layers.Input(shape=(len(symptom_severity_dict),), name='symptom_input')\n\n# Neural network component\nneural_network_output = layers.Dense(256, activation='relu')(symptom_input)\nneural_network_output = layers.Dropout(0.5)(neural_network_output)\nneural_network_output = layers.Dense(128, activation='relu')(neural_network_output)\nneural_network_output = layers.Dropout(0.5)(neural_network_output)\nneural_network_output = layers.Dense(64, activation='relu')(neural_network_output)\nneural_network_output = layers.Dropout(0.5)(neural_network_output)\nneural_network_output = layers.Dense(32, activation='relu')(neural_network_output)\nneural_network_output = layers.Dropout(0.5)(neural_network_output)\nneural_network_output = layers.Dense(len(disease_symptom_dict), activation='softmax', name='neural_network_output')(neural_network_output)\n\n# Symbolic reasoning component\n# Create the hybrid model\nsymbolic_rules_output = layers.Dense(len(disease_symptom_dict), activation='softmax', name='symbolic_rules_output')(symptom_input)\n\n# Combine neural network and symbolic reasoning outputs using an average layer\ncombined_output = layers.Average(name='combined_output')([neural_network_output, symbolic_rules_output])\n\n# Create the hybrid model\nmodel = Model(inputs=[symptom_input], outputs=[combined_output])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Convert disease-symptom dictionary to training data\nX_train = []\ny_train = []\nfor disease, symptoms in disease_symptom_dict.items():\n    X_train.append(encode_symptoms(symptoms))\n    y_train.append(np.array([1 if d == disease else 0 for d in disease_symptom_dict.keys()]))\nX_train = np.array(X_train)\ny_train = np.array(y_train)\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=100, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:19:37.703405Z","iopub.execute_input":"2023-05-31T15:19:37.703800Z","iopub.status.idle":"2023-05-31T15:19:43.557083Z","shell.execute_reply.started":"2023-05-31T15:19:37.703771Z","shell.execute_reply":"2023-05-31T15:19:43.555644Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/100\n3/3 [==============================] - 1s 7ms/step - loss: 3.8289 - accuracy: 0.0244\nEpoch 2/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.7527 - accuracy: 0.0488\nEpoch 3/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.6902 - accuracy: 0.0000e+00\nEpoch 4/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.6229 - accuracy: 0.0488\nEpoch 5/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.4199 - accuracy: 0.0488\nEpoch 6/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.5333 - accuracy: 0.0244\nEpoch 7/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.3509 - accuracy: 0.0976\nEpoch 8/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.4009 - accuracy: 0.1463\nEpoch 9/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.3124 - accuracy: 0.1220\nEpoch 10/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.2522 - accuracy: 0.1463\nEpoch 11/100\n3/3 [==============================] - 0s 4ms/step - loss: 3.1476 - accuracy: 0.1707\nEpoch 12/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.1771 - accuracy: 0.2927\nEpoch 13/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.0114 - accuracy: 0.3171\nEpoch 14/100\n3/3 [==============================] - 0s 5ms/step - loss: 3.0463 - accuracy: 0.3171\nEpoch 15/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.9964 - accuracy: 0.3171\nEpoch 16/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.9378 - accuracy: 0.2683\nEpoch 17/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.8606 - accuracy: 0.3171\nEpoch 18/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.8430 - accuracy: 0.3659\nEpoch 19/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.7048 - accuracy: 0.4146\nEpoch 20/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.6861 - accuracy: 0.4146\nEpoch 21/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.5851 - accuracy: 0.4634\nEpoch 22/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.5639 - accuracy: 0.4878\nEpoch 23/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.5359 - accuracy: 0.5122\nEpoch 24/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.4228 - accuracy: 0.5366\nEpoch 25/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.3515 - accuracy: 0.5366\nEpoch 26/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.4291 - accuracy: 0.5122\nEpoch 27/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.3215 - accuracy: 0.5610\nEpoch 28/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.3690 - accuracy: 0.5366\nEpoch 29/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.3133 - accuracy: 0.5610\nEpoch 30/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.2255 - accuracy: 0.5610\nEpoch 31/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.2168 - accuracy: 0.5610\nEpoch 32/100\n3/3 [==============================] - 0s 5ms/step - loss: 2.1438 - accuracy: 0.5854\nEpoch 33/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.1024 - accuracy: 0.6341\nEpoch 34/100\n3/3 [==============================] - 0s 4ms/step - loss: 2.0296 - accuracy: 0.6341\nEpoch 35/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.9625 - accuracy: 0.6829\nEpoch 36/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.9735 - accuracy: 0.6098\nEpoch 37/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.9174 - accuracy: 0.7073\nEpoch 38/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.8825 - accuracy: 0.7561\nEpoch 39/100\n3/3 [==============================] - 0s 3ms/step - loss: 1.8989 - accuracy: 0.7073\nEpoch 40/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.7946 - accuracy: 0.7073\nEpoch 41/100\n3/3 [==============================] - 0s 3ms/step - loss: 1.7737 - accuracy: 0.7805\nEpoch 42/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.7882 - accuracy: 0.7805\nEpoch 43/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.7110 - accuracy: 0.8537\nEpoch 44/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.7428 - accuracy: 0.8780\nEpoch 45/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.6498 - accuracy: 0.8049\nEpoch 46/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.6770 - accuracy: 0.8780\nEpoch 47/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.6925 - accuracy: 0.7805\nEpoch 48/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.5763 - accuracy: 0.8780\nEpoch 49/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.6497 - accuracy: 0.8049\nEpoch 50/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.5515 - accuracy: 0.8537\nEpoch 51/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.6169 - accuracy: 0.8293\nEpoch 52/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.5305 - accuracy: 0.9024\nEpoch 53/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.5183 - accuracy: 0.8537\nEpoch 54/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.4234 - accuracy: 0.9512\nEpoch 55/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.3849 - accuracy: 0.9268\nEpoch 56/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.4071 - accuracy: 0.9268\nEpoch 57/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.4148 - accuracy: 0.9512\nEpoch 58/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.3290 - accuracy: 0.9512\nEpoch 59/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.3071 - accuracy: 0.9024\nEpoch 60/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.3021 - accuracy: 0.9268\nEpoch 61/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.2981 - accuracy: 0.9024\nEpoch 62/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.2779 - accuracy: 0.9268\nEpoch 63/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.3146 - accuracy: 0.9756\nEpoch 64/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.2137 - accuracy: 0.9512\nEpoch 65/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.2828 - accuracy: 0.8780\nEpoch 66/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.2208 - accuracy: 0.9268\nEpoch 67/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.2134 - accuracy: 0.9512\nEpoch 68/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.2361 - accuracy: 0.9268\nEpoch 69/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.1961 - accuracy: 0.9268\nEpoch 70/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.1869 - accuracy: 0.9268\nEpoch 71/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.1120 - accuracy: 0.9512\nEpoch 72/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.1306 - accuracy: 0.9512\nEpoch 73/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.9756\nEpoch 74/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0980 - accuracy: 0.9756\nEpoch 75/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.0763 - accuracy: 0.9756\nEpoch 76/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0410 - accuracy: 0.9756\nEpoch 77/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.9756\nEpoch 78/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0558 - accuracy: 1.0000\nEpoch 79/100\n3/3 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.9756\nEpoch 80/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0586 - accuracy: 0.9756\nEpoch 81/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.0448 - accuracy: 0.9268\nEpoch 82/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0191 - accuracy: 0.9756\nEpoch 83/100\n3/3 [==============================] - 0s 5ms/step - loss: 1.0061 - accuracy: 0.9512\nEpoch 84/100\n3/3 [==============================] - 0s 4ms/step - loss: 1.0002 - accuracy: 0.9756\nEpoch 85/100\n3/3 [==============================] - 0s 3ms/step - loss: 0.9886 - accuracy: 0.9756\nEpoch 86/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9792 - accuracy: 0.9512\nEpoch 87/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9763 - accuracy: 1.0000\nEpoch 88/100\n3/3 [==============================] - 0s 3ms/step - loss: 0.9821 - accuracy: 0.9512\nEpoch 89/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9531 - accuracy: 0.9512\nEpoch 90/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9245 - accuracy: 0.9756\nEpoch 91/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9431 - accuracy: 0.9756\nEpoch 92/100\n3/3 [==============================] - 0s 5ms/step - loss: 0.9425 - accuracy: 0.9756\nEpoch 93/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9144 - accuracy: 0.9756\nEpoch 94/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9035 - accuracy: 1.0000\nEpoch 95/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9290 - accuracy: 1.0000\nEpoch 96/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.9756\nEpoch 97/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.9203 - accuracy: 0.9756\nEpoch 98/100\n3/3 [==============================] - 0s 5ms/step - loss: 0.9310 - accuracy: 0.9756\nEpoch 99/100\n3/3 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.9756\nEpoch 100/100\n3/3 [==============================] - 0s 5ms/step - loss: 0.8887 - accuracy: 0.9512\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ddfd373abc0>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to get feature importance based on model weights\ndef get_feature_importance(model, user_symptoms):\n    feature_names = list(symptom_severity_dict.keys())\n    user_symptom_indices = np.array([symptom_to_index[symptom] for symptom in user_symptoms if symptom in symptom_to_index])\n    feature_importance = np.abs(model.get_weights()[0]).sum(axis=1)\n    user_symptom_importance = feature_importance[user_symptom_indices]\n    sorted_indices = np.argsort(user_symptom_importance)[::-1]\n    sorted_features = [feature_names[i] for i in user_symptom_indices[sorted_indices]]\n    sorted_importance = user_symptom_importance[sorted_indices]\n    return sorted_features, sorted_importance\n\n\n# Function to predict disease based on symptoms using the trained model\ndef predict_disease(symptoms):\n    encoded_symptoms = encode_symptoms(symptoms)\n    predicted = model.predict(np.array([encoded_symptoms]))\n    disease_index = np.argmax(predicted)\n    predicted_disease = list(disease_symptom_dict.keys())[disease_index]\n\n    # Add explanation within the prediction process\n    print(\"The model predicted the disease based on the following symptoms:\")\n    for symptom in symptoms:\n        print(\"- \" + symptom)\n    print(\"The predicted disease is: \" + predicted_disease)\n\n    return predicted_disease\n\n\ndef explain_decision(symptoms, user_symptoms):\n    print(\"symptoms\", symptoms)\n    encoded_symptoms = encode_symptoms(symptoms)\n    predicted = model.predict(np.array([encoded_symptoms]))\n    disease_index = np.argmax(predicted)\n    predicted_disease = list(disease_symptom_dict.keys())[disease_index]\n    top_diseases_indices = np.argsort(predicted)[0][-5:][::-1]\n    top_diseases = [list(disease_symptom_dict.keys())[index] for index in top_diseases_indices]\n    \n    # Get disease description and precautions\n    disease_description = get_disease_description(predicted_disease)\n    disease_precautions = get_disease_precautions(predicted_disease)\n    \n    # Check for other diseases with the same symptoms\n    potential_diseases = []\n    for disease, symptoms in disease_symptom_dict.items():\n        if set(user_symptoms).issubset(set(symptoms)):\n            potential_diseases.append(disease)\n    print(\"POTENTIAL\", potential_diseases)\n    \n    diseases_same = []\n    for disease in potential_diseases:\n        dsymptoms = disease_symptom_dict[disease]\n        check = all(item in dsymptoms for item in user_symptoms)\n        if check is True:\n            print()\n            diseases_same.append(disease)\n            print()\n    \n    print(\"TOP\", top_diseases)\n    for i in top_diseases:\n        diseases_same.append(i)\n    \n    diseases_same = set(diseases_same)\n    diseases_same = list(diseases_same)\n    count = len(diseases_same)\n    \n    print()\n    print(\"Total diseases with these symptoms\", count)\n    for i in diseases_same:\n        print(i)\n    print()\n    \n    check = input(\"Do you wanna check for other diseases?\")\n    if check == 'yes':\n        for i in diseases_same:\n            print(\"DISEASE\", i)\n            print(\"symptoms\", disease_symptom_dict[i])\n            dsd = set(disease_symptom_dict[i])\n            print(\"user symptoms\", user_symptoms)\n            us = set(user_symptoms)\n            uncommon_symptoms = list(dsd.difference(us))\n            print(\"uncommon symptoms\", uncommon_symptoms)\n            for j in uncommon_symptoms[:2]:\n                print(\"What about this?\", j)\n                ans = input(\"do u have this? (yes or no)\")\n                if ans == 'yes':\n                    user_symptoms.append(j)\n    else:\n        print(\"Hopefully we got that right ;)\")\n        \n    encoded_symptoms = encode_symptoms(user_symptoms)\n    predicted = model.predict(np.array([encoded_symptoms]))\n    disease_index = np.argmax(predicted)\n    predicted_disease = list(disease_symptom_dict.keys())[disease_index]\n\n    # Get disease description and precautions\n    disease_description = get_disease_description(predicted_disease)\n    disease_precautions = get_disease_precautions(predicted_disease)\n    \n    # Generate detailed explanation\n    explanation = f\"Based on the given symptoms, the model predicts the disease as '{predicted_disease}'.\\n\\n\"\n\n    # Feature Importance\n    explanation += \"Feature Importance:\\n\"\n    features, importance = get_feature_importance(model, user_symptoms)\n    explanation += \"The most important symptoms for the prediction are:\\n\"\n    for feature, score in zip(features, importance):\n        explanation += f\"- {feature}: Importance {score}\\n\"\n    explanation += \"\\n\"\n\n    # Neurosymbolic Explanation\n    explanation += \"Neurosymbolic Explanation:\\n\"\n    explanation += \"The model combines neural network predictions and symbolic reasoning to arrive at the disease prediction. \"\n    explanation += \"The neural network analyzes the severity of symptoms and learns patterns from the training data. \"\n    explanation += \"The symbolic reasoning component uses predefined rules and relationships between symptoms and diseases to infer the most likely disease.\\n\\n\"\n\n    # Symptom Analysis\n    explanation += \"Symptom Analysis:\\n\"\n    explanation += \"The model considers the following symptoms and their severities:\\n\"\n    for symptom, severity in zip(symptom_severity_dict.keys(), encoded_symptoms):\n        if symptom in user_symptoms:\n            explanation += f\"- {symptom}: Severity {severity}\\n\"\n    explanation += \"\\n\"\n\n    # Disease-Symptom Information\n    explanation += \"Disease-Symptom Information:\\n\"\n    explanation += \"The model incorporates information about diseases and their associated symptoms from the dataset.\\n\"\n    explanation += \"It learns the relationships between symptoms and diseases through the training process.\\n\"\n    disease_symptoms = disease_symptom_dict[predicted_disease]\n\n    # Disease Description\n    explanation += \"Description:\\n\"\n    explanation += f\"The predicted disease, '{predicted_disease}', is described as follows:\\n\"\n    explanation += f\"{disease_description}\\n\\n\"\n\n    # Precautions\n    explanation += \"Precautions:\\n\"\n    for i, precaution in enumerate(disease_precautions):\n        explanation += f\"{i + 1}. {precaution}\\n\"\n\n    return explanation\n\ndef get_disease_description(disease):\n    description = disease_description_df.loc[disease_description_df['Disease'] == disease, 'Description'].values[0]\n    return description\n\n# Function to get disease precautions\ndef get_disease_precautions(disease):\n    precautions = disease_precaution_df.loc[disease_precaution_df['Disease'] == disease].drop('Disease', axis=1).values[0]\n    return precautions","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:19:45.571939Z","iopub.execute_input":"2023-05-31T15:19:45.572319Z","iopub.status.idle":"2023-05-31T15:19:45.593685Z","shell.execute_reply.started":"2023-05-31T15:19:45.572290Z","shell.execute_reply":"2023-05-31T15:19:45.592389Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Example usage\npatient_symptoms = ['itching','skin_rash']\npredicted_disease = predict_disease(patient_symptoms)\nexplanation = explain_decision(patient_symptoms, patient_symptoms)\nprint('Patient Symptoms:', patient_symptoms)\nprint('Predicted Disease:', predicted_disease)\nprint('Explanation:\\n', explanation)\nprint('Attention Visualization')\nsorted_features, sorted_importance = get_feature_importance(model, patient_symptoms)\nprint('Feature Importance:')\nfor feature, importance in zip(sorted_features, sorted_importance):\n    print(f'- {feature}: {importance}')","metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:19:52.366112Z","iopub.execute_input":"2023-05-31T15:19:52.366490Z","iopub.status.idle":"2023-05-31T15:19:59.095262Z","shell.execute_reply.started":"2023-05-31T15:19:52.366462Z","shell.execute_reply":"2023-05-31T15:19:59.093987Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 99ms/step\nThe model predicted the disease based on the following symptoms:\n- itching\n- skin_rash\nThe predicted disease is: Drug Reaction\nsymptoms ['itching', 'skin_rash']\n1/1 [==============================] - 0s 18ms/step\nPOTENTIAL ['Fungal infection', 'Drug Reaction', 'Chicken pox']\n\n\n\n\n\n\nTOP ['Drug Reaction', 'Fungal infection', 'Acne', 'Chicken pox', 'Gastroenteritis']\n\nTotal diseases with these symptoms 5\nFungal infection\nDrug Reaction\nChicken pox\nAcne\nGastroenteritis\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Do you wanna check for other diseases? No\n"},{"name":"stdout","text":"Hopefully we got that right ;)\n1/1 [==============================] - 0s 18ms/step\nPatient Symptoms: ['itching', 'skin_rash']\nPredicted Disease: Drug Reaction\nExplanation:\n Based on the given symptoms, the model predicts the disease as 'Drug Reaction'.\n\nFeature Importance:\nThe most important symptoms for the prediction are:\n- skin_rash: Importance 16.518003463745117\n- itching: Importance 15.642765998840332\n\nNeurosymbolic Explanation:\nThe model combines neural network predictions and symbolic reasoning to arrive at the disease prediction. The neural network analyzes the severity of symptoms and learns patterns from the training data. The symbolic reasoning component uses predefined rules and relationships between symptoms and diseases to infer the most likely disease.\n\nSymptom Analysis:\nThe model considers the following symptoms and their severities:\n- itching: Severity 1.0\n- skin_rash: Severity 3.0\n\nDisease-Symptom Information:\nThe model incorporates information about diseases and their associated symptoms from the dataset.\nIt learns the relationships between symptoms and diseases through the training process.\nDescription:\nThe predicted disease, 'Drug Reaction', is described as follows:\nAn adverse drug reaction (ADR) is an injury caused by taking medication. ADRs may occur following a single dose or prolonged administration of a drug or result from the combination of two or more drugs.\n\nPrecautions:\n1. stop irritation\n2. consult nearest hospital\n3. stop taking drug\n4. follow up\n\nAttention Visualization\nFeature Importance:\n- skin_rash: 16.518003463745117\n- itching: 15.642765998840332\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}